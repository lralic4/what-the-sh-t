{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x13f229ac0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "cudnn.benchmark = True\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = './training-data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()   # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "        print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=2):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n",
    "model_ft.fc = nn.Linear(num_ftrs, 7)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.0426 Acc: 0.2353\n",
      "val Loss: 1.9981 Acc: 0.2667\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.7090 Acc: 0.2941\n",
      "val Loss: 2.1044 Acc: 0.2000\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.4711 Acc: 0.4118\n",
      "val Loss: 2.0368 Acc: 0.2000\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.2312 Acc: 0.5098\n",
      "val Loss: 1.8608 Acc: 0.4000\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.8992 Acc: 0.7255\n",
      "val Loss: 2.1208 Acc: 0.4667\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.1375 Acc: 0.5686\n",
      "val Loss: 2.2201 Acc: 0.4000\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.6895 Acc: 0.8039\n",
      "val Loss: 2.3860 Acc: 0.2667\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.7754 Acc: 0.7059\n",
      "val Loss: 2.2232 Acc: 0.5333\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.9433 Acc: 0.6863\n",
      "val Loss: 2.2010 Acc: 0.5333\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.6162 Acc: 0.8824\n",
      "val Loss: 2.1794 Acc: 0.4667\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.7427 Acc: 0.7647\n",
      "val Loss: 2.1308 Acc: 0.4667\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.8455 Acc: 0.7255\n",
      "val Loss: 2.1035 Acc: 0.4667\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.5730 Acc: 0.8627\n",
      "val Loss: 2.1071 Acc: 0.4000\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.7390 Acc: 0.7451\n",
      "val Loss: 2.1782 Acc: 0.4000\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.7925 Acc: 0.6863\n",
      "val Loss: 2.0582 Acc: 0.5333\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.6049 Acc: 0.8039\n",
      "val Loss: 2.0495 Acc: 0.4667\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.7094 Acc: 0.7843\n",
      "val Loss: 2.0842 Acc: 0.4667\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.5407 Acc: 0.9020\n",
      "val Loss: 2.1032 Acc: 0.4667\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.5927 Acc: 0.8235\n",
      "val Loss: 2.0705 Acc: 0.4667\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.6771 Acc: 0.8431\n",
      "val Loss: 2.1130 Acc: 0.5333\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.6765 Acc: 0.8431\n",
      "val Loss: 2.1138 Acc: 0.4000\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.7467 Acc: 0.8039\n",
      "val Loss: 2.0352 Acc: 0.4000\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.8579 Acc: 0.7059\n",
      "val Loss: 2.1342 Acc: 0.4000\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.5575 Acc: 0.8235\n",
      "val Loss: 2.1491 Acc: 0.4000\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.7083 Acc: 0.7843\n",
      "val Loss: 2.0924 Acc: 0.3333\n",
      "\n",
      "Training complete in 20m 31s\n",
      "Best val Acc: 0.533333\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './testimage1.jpeg'\n",
    "\n",
    "img = Image.open(img_path)\n",
    "img = data_transforms['val'](img)\n",
    "img = img.unsqueeze(0)\n",
    "img = img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(img)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    conf, _ = torch.max(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type-6\n",
      "0.4143231213092804\n"
     ]
    }
   ],
   "source": [
    "print(class_names[preds[0]])\n",
    "print(conf.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
